{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "-cp253OYk0zk"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "#@markdown # DeepLab inference\n",
        "!python -m pip install abraia\n",
        "!python -m pip install onnxruntime\n",
        "\n",
        "import os\n",
        "if not os.getenv('ABRAIA_ID') and not os.getenv('ABRAIA_KEY'):\n",
        "    abraia_id = ''  #@param {type: \"string\"}\n",
        "    abraia_key = ''  #@param {type: \"string\"}\n",
        "    %env ABRAIA_ID=$abraia_id\n",
        "    %env ABRAIA_KEY=$abraia_key\n",
        "\n",
        "from abraia import Multiple\n",
        "\n",
        "multiple = Multiple()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "YkUzYb9dmcXO",
        "outputId": "e3773c24-b739-4865-d367-e397f991c814"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "circles/*.{png,jpg}\n",
            "circles/img_199.png\n",
            "{'task': 'segment', 'inputShape': [1, 3, 128, 128], 'classes': ['circle']}\n",
            "circles/img_199.png [{'label': 'circle', 'confidence': 0.9606869220733643, 'box': [67.13153600692749, 23.663557469844818, 93.73035192489624, 50.90367704629898], 'color': '#D0021B', 'polygon': [(70, 24), (68, 26), (67, 26), (67, 46), (68, 46), (70, 48), (70, 49), (72, 49), (73, 50), (73, 51), (87, 51), (87, 50), (88, 49), (90, 49), (90, 48), (92, 46), (93, 46), (93, 26), (92, 26), (90, 24)]}]\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHgAAAB4CAIAAAC2BqGFAAABjklEQVR4nO3Zu07DMBQG4JQyd0ai70CfqzNzEJ2ZeS76DlRiZqcwWIqipBfnUqe43zdZSnxk/TmyI7koAAAAAPIxm3oBo/m4e5x6CafcTb2AW3E/9QIm8PTzWRTFdr7s9H4QP6s+cTtf2jpi9fs82/kyDDLv6HpPFYd6sxFHexxZ+ayc9+h6D1bjRi6NpwfHMZXbGk8z7+ggpunCO5HtHByLuFHzJraOoOv2GjnrdMHG9MwPwxN7dFsVytlZ9cYvjifur2MCOR+GV0XQidzEYdjPar8bsVqGQb//fofBZrOJn1WWZRisZ4vx15Tf1tEv5fr7VYVx5RZ00DXlIbMiZRj0kLwul3Vu/9EPr8/DS329vBVjH4YZdvR1EnQigk5E0IkIOhFBJyLoRASdiKATEXQigk5E0IkIOhFBJyLoRASdSG5BV3esE1Y4KLeg17PFkKTKsnQLHmW13/XOOqQ87g1WJbc7wxG5M/yX8unotk49fqEdAwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA6OgPnMCXFScjRe4AAAAASUVORK5CYII=",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=120x120>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "import onnxruntime as ort\n",
        "import numpy as np\n",
        "import math\n",
        "import cv2\n",
        "import re\n",
        "\n",
        "\n",
        "def get_color(idx):\n",
        "    colors = ['#D0021B', '#F5A623', '#F8E71C', '#8B572A', '#7ED321',\n",
        "    '#417505', '#BD10E0', '#9013FE', '#4A90E2', '#50E3C2', '#B8E986',\n",
        "    '#000000', '#545454', '#737373', '#A6A6A6', '#D9D9D9', '#FFFFFF']\n",
        "    return colors[idx % len(colors)]\n",
        "\n",
        "def hex_to_rgb(hex):\n",
        "    h = hex.lstrip('#')\n",
        "    return tuple(int(h[i:i+2], 16) for i in (0, 2, 4))\n",
        "\n",
        "def load_image(path):\n",
        "    return Image.open(multiple.cache_file(path))\n",
        "\n",
        "def resize(img, size):\n",
        "    width = size if img.height > img.width else round(size * img.width / img.height)\n",
        "    height = round(size * img.height / img.width) if img.height > img.width else size\n",
        "    return img.resize((width, height))\n",
        "\n",
        "def crop(img, size):\n",
        "    left, top = (img.width - size) // 2, (img.height - size) // 2\n",
        "    right, bottom = left + size, top + size\n",
        "    return img.crop((left, top, right, bottom))\n",
        "\n",
        "def normalize(img, mean, std):\n",
        "    img = (np.array(img) / 255. - np.array(mean)) / np.array(std)\n",
        "    return img.astype(np.float32)\n",
        "\n",
        "def preprocess(img):\n",
        "    img = img.convert('RGB')\n",
        "    img = resize(img, 256)\n",
        "    img = crop(img, 224)\n",
        "    img = normalize(img, [0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    return np.expand_dims(img.transpose((2, 0, 1)), axis=0)\n",
        "\n",
        "def softmax(x):\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x / e_x.sum(axis=0)\n",
        "\n",
        "def postprocess(outputs, classes):\n",
        "    probs = softmax(outputs[0].flatten())\n",
        "    idx = np.argmax(probs)\n",
        "    results = [{'label': classes[idx], 'confidence': probs[idx], 'color': get_color(idx)}]\n",
        "    return results\n",
        "\n",
        "\n",
        "def prepare_input(img, shape):\n",
        "    \"\"\"Converts the input image to RGB an return a (3, height, width) tensor.\"\"\"\n",
        "    img = img.convert(\"RGB\")\n",
        "    img = img.resize((shape[3], shape[2]))\n",
        "    input = np.array(img) / 255.0\n",
        "    input = input.transpose(2, 0, 1)\n",
        "    input = input.reshape(shape)\n",
        "    return input.astype(np.float32)\n",
        "\n",
        "def intersection(box1, box2):\n",
        "    \"\"\"Calculates the intersection area of two boxes.\"\"\"\n",
        "    box1_x1, box1_y1, box1_x2, box1_y2 = box1\n",
        "    box2_x1, box2_y1, box2_x2, box2_y2 = box2\n",
        "    x1, y1 = max(box1_x1, box2_x1), max(box1_y1, box2_y1)\n",
        "    x2, y2 = min(box1_x2, box2_x2), min(box1_y2, box2_y2)\n",
        "    return (x2 - x1) * (y2 - y1)\n",
        "\n",
        "def union(box1, box2):\n",
        "    \"\"\"Calculates the union area of two boxes.\"\"\"\n",
        "    box1_x1, box1_y1, box1_x2, box1_y2 = box1\n",
        "    box2_x1, box2_y1, box2_x2, box2_y2 = box2\n",
        "    box1_area = (box1_x2 - box1_x1) * (box1_y2 - box1_y1)\n",
        "    box2_area = (box2_x2 - box2_x1) * (box2_y2 - box2_y1)\n",
        "    return box1_area + box2_area - intersection(box1, box2)\n",
        "\n",
        "def iou(box1, box2):\n",
        "    \"\"\"Calculates \"Intersection-over-union\" coefficient for specified two boxes.\"\"\"\n",
        "    return intersection(box1, box2) / union(box1, box2)\n",
        "\n",
        "def sigmoid_mask(z):\n",
        "    mask = 1 / (1 + np.exp(-z))\n",
        "    return 255 * (mask > 0.5).astype('uint8')\n",
        "\n",
        "def get_mask(row, box, img_width, img_height):\n",
        "    \"\"\"Extracts the segmentation mask for an object (box) in a row.\"\"\"\n",
        "    size = round(math.sqrt(row.shape[0]))\n",
        "    mask = row.reshape(size, size)\n",
        "    mask = sigmoid_mask(mask)\n",
        "    x1, y1, x2, y2 = box\n",
        "    mask_x1, mask_y1 = round(x1 / img_width * size), round(y1 / img_height * size)\n",
        "    mask_x2, mask_y2 = round(x2 / img_width * size), round(y2 / img_height * size)\n",
        "    mask = mask[mask_y1:mask_y2, mask_x1:mask_x2]\n",
        "    img_mask = Image.fromarray(mask, \"L\")\n",
        "    img_mask = img_mask.resize((round(x2-x1), round(y2-y1)))\n",
        "    mask = np.array(img_mask)\n",
        "    return mask\n",
        "\n",
        "def get_polygon(mask, origin):\n",
        "    \"\"\"Calculates the bounding polygon based on the segmentation mask.\"\"\"\n",
        "    contours = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    polygon = [[int(contour[0][0]), int(contour[0][1])] for contour in contours[0][0]]\n",
        "    polygon = [(int(origin[0] + point[0]), int(origin[1] + point[1])) for point in polygon]\n",
        "    return polygon\n",
        "\n",
        "def process_output(outputs, size, shape, classes):\n",
        "    \"\"\"Converts the RAW model output from YOLOv8 to an array of detected\n",
        "    objects, containing the bounding box, label and the probability.\n",
        "    \"\"\"\n",
        "    img_width, img_height = size\n",
        "    model_width, model_height = shape[3], shape[2]\n",
        "    output0 = outputs[0][0].astype(\"float\")\n",
        "    output0 = output0.transpose()\n",
        "    if len(outputs) == 2:\n",
        "        output1 = outputs[1][0].astype(\"float\")\n",
        "        output1 = output1.reshape(output1.shape[0], output1.shape[1] * output1.shape[2])\n",
        "\n",
        "    objects = []\n",
        "    for row in output0:\n",
        "        xc, yc, w, h = row[:4]\n",
        "        probs = row[4:4+len(classes)]\n",
        "        idx = probs.argmax()\n",
        "        if probs[idx] < 0.5:\n",
        "            continue\n",
        "        x1, y1 = (xc - w/2) / model_width * img_width, (yc - h/2) / model_height * img_height\n",
        "        x2, y2 = (xc + w/2) / model_width * img_width, (yc + h/2) / model_height * img_height\n",
        "        obj = {'label': classes[idx], 'confidence': probs[idx], 'box': [x1, y1, x2, y2], 'color': get_color(idx)}\n",
        "        if len(outputs) == 2:\n",
        "            obj['mask'] = row[4+len(classes):]\n",
        "        objects.append(obj)\n",
        "\n",
        "    objects.sort(key=lambda x: x['confidence'], reverse=True)\n",
        "    results = []\n",
        "    while len(objects) > 0:\n",
        "        results.append(objects[0])\n",
        "        objects = [obj for obj in objects if iou(obj['box'], objects[0]['box']) < 0.5]\n",
        "\n",
        "    for result in results:\n",
        "        if len(outputs) == 2:\n",
        "            mask = result['mask'] @ output1\n",
        "            mask = get_mask(mask, (x1, y1, x2, y2), img_width, img_height)\n",
        "            result['polygon'] = get_polygon(mask, (x1, y1))\n",
        "            result.pop('mask', None)\n",
        "    return results\n",
        "\n",
        "\n",
        "def render_results(img, results):\n",
        "    draw = ImageDraw.Draw(img, \"RGBA\")\n",
        "    for result in results:\n",
        "        x1, y1 = 0, 0\n",
        "        label = result.get('label')\n",
        "        prob = result.get('confidence')\n",
        "        color = hex_to_rgb(result.get('color'))\n",
        "        if (label):\n",
        "            if result.get('polygon'):\n",
        "                draw.polygon(result['polygon'], fill=(color[0], color[1], color[2], 125), outline=color, width=1)\n",
        "            if result.get('box'):\n",
        "                [x1, y1, x2, y2] = result['box']\n",
        "                draw.rectangle([(x1, y1), (x2, y2)], outline=color, width=2)\n",
        "            text = f\" {label} {round(100 * prob, 1)}% \"\n",
        "            font = ImageFont.load_default()\n",
        "            y1 = max(y1 - 11, 0)\n",
        "            bbox = draw.textbbox((x1, y1), text, font=font)\n",
        "            draw.rectangle(bbox, fill=color)\n",
        "            draw.text((x1, y1), text, font=font)\n",
        "    return img\n",
        "\n",
        "\n",
        "class Model:\n",
        "    def load_model(self, dataset, model_name):\n",
        "        self.config = multiple.load_json(f\"{dataset}/{model_name}.json\")\n",
        "        model_src = multiple.cache_file(f\"{dataset}/{model_name}.onnx\")\n",
        "        self.ort_session = ort.InferenceSession(model_src, providers=['CPUExecutionProvider'])\n",
        "\n",
        "    def run_model(self, img):\n",
        "        print(self.config)\n",
        "        if self.config.get('task'):\n",
        "            input = prepare_input(img, self.config['inputShape'])\n",
        "            outputs = self.ort_session.run(None, {\"images\": input})\n",
        "            return process_output(outputs, img.size, self.config['inputShape'], self.config['classes'])\n",
        "        input = preprocess(img)\n",
        "        outputs = self.ort_session.run(None, {\"input\": input})\n",
        "        results = postprocess(outputs, self.config['classes'])\n",
        "        return results\n",
        "\n",
        "\n",
        "dataset = 'screws'\n",
        "model_name = 'model_ft'\n",
        "dataset = 'circles'\n",
        "model_name = 'yolov8n-seg'\n",
        "print(f\"{dataset}/*.{{png,jpg}}\")\n",
        "\n",
        "files = multiple.list_files(f\"{dataset}/*.png\")[0]\n",
        "path = files[0]['path']\n",
        "src = os.path.basename(path)\n",
        "print(path)\n",
        "\n",
        "model = Model()\n",
        "model.load_model(dataset, model_name)\n",
        "\n",
        "img = load_image(path).convert('RGB')\n",
        "results = model.run_model(img)\n",
        "print(path, results)\n",
        "\n",
        "img = render_results(img, results)\n",
        "img"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
