{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DeepHSIClassification.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "tAxf4dEgakM1"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.10 64-bit ('.venv': venv)"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "interpreter": {
      "hash": "4ceb193afc32d6373bcd90208dd4e2f53a134ecba4f4a2a17c3a709dde462eeb"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# MULTIPLE - Hybrid Spectral Net"
      ],
      "metadata": {
        "id": "VNJ5YSjlipuZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "%%capture\n",
        "!python -m pip install -U abraia\n",
        "!python -m pip install wget\n",
        "\n",
        "import os\n",
        "\n",
        "if not os.getenv('ABRAIA_KEY'):\n",
        "   #@markdown <a href=\"https://abraia.me/console/settings\" target=\"_blank\">Get your ABRAIA_KEY</a>\n",
        "   abraia_key = ''  #@param {type: \"string\"}\n",
        "   %env ABRAIA_KEY=$abraia_key\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from abraia import Multiple, hsi\n",
        "\n",
        "plt.rcParams['figure.figsize'] = [12, 6]\n",
        "plt.rcParams['figure.dpi'] = 100\n",
        " \n",
        "multiple = Multiple()"
      ],
      "outputs": [],
      "metadata": {
        "id": "U3pgl9pajiZZ",
        "cellView": "form"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data loading"
      ],
      "metadata": {
        "id": "qz4Fyz4QakMl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "source": [
        "dataset = 'IP'\n",
        "X, y, class_names = hsi.load_dataset(dataset)\n",
        "X.shape, y.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((145, 145, 200), (145, 145))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "metadata": {
        "id": "dZXbSukVakMm",
        "outputId": "97b82544-4919-4592-d5d9-a733e3baa4bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "source": [
        "def padWithZeros(X, margin=2):\n",
        "    newX = np.zeros((X.shape[0] + 2 * margin, X.shape[1] + 2* margin, X.shape[2]))\n",
        "    newX[margin:X.shape[0] + margin, margin:X.shape[1] + margin, :] = X\n",
        "    return newX\n",
        "\n",
        "def patch(data, height_index, width_index, patch_size):\n",
        "    height_slice = slice(height_index, height_index + patch_size)\n",
        "    width_slice = slice(width_index, width_index + patch_size)\n",
        "    return data[height_slice, width_slice, :]\n",
        "\n",
        "def create_patches(X, patch_size):\n",
        "    patches = []\n",
        "    width, height = X.shape[1], X.shape[0]\n",
        "    X = padWithZeros(X, patch_size // 2)\n",
        "    for i in range(height):\n",
        "        for j in range(width):\n",
        "            image_patch = patch(X, i, j, patch_size)\n",
        "            patches.append(image_patch.reshape(image_patch.shape + (1,)).astype('float32'))\n",
        "    return np.array(patches)\n",
        "\n",
        "def create_image_cubes(X, y, patch_size):\n",
        "    width, height = X.shape[1], X.shape[0]\n",
        "    patchesData = create_patches(X, patch_size)\n",
        "    labels = []\n",
        "    for i in range(height):\n",
        "        for j in range(width):\n",
        "            labels.append(y[i, j])\n",
        "    patchesLabels = np.array(labels)\n",
        "    return patchesData, patchesLabels\n",
        "\n",
        "def generate_training_data(X, y, window_size, K, train_ratio=0.3):\n",
        "    X = hsi.principal_components(X, n_components=K)\n",
        "    X, y = create_image_cubes(X, y, window_size)\n",
        "    X_train, X_test, y_train, y_test = hsi.split_train_test(X, y, train_ratio)\n",
        "    X_train = X_train.reshape(-1, window_size, window_size, K, 1)\n",
        "    X_test = X_test.reshape(-1, window_size, window_size, K, 1)\n",
        "    return X_train, X_test, y_train, y_test"
      ],
      "outputs": [],
      "metadata": {
        "id": "1OajF09gakMq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "source": [
        "patch_size = 25\n",
        "K = 30 if dataset == 'IP' else 15\n",
        "X_train, X_test, y_train, y_test = generate_training_data(X, y, patch_size, K, train_ratio=0.3)\n",
        "X_train.shape, y_train.shape"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYxRpY76akMs",
        "outputId": "c0eb1387-bf93-4a07-87da-145892160b1c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model training and validation"
      ],
      "metadata": {
        "id": "UgylPCysakMw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "from tensorflow import keras\n",
        "from keras.models import Model\n",
        "from keras.utils import np_utils\n",
        "from keras.layers import Input, Conv2D, Conv3D, Flatten, Dense, Reshape, Dropout\n",
        "\n",
        "def create_model(window_size, n_bands, output_units):\n",
        "    ## input layer\n",
        "    input_layer = Input((window_size, window_size, n_bands, 1))\n",
        "    ## convolutional layers\n",
        "    conv_layer1 = Conv3D(filters=8, kernel_size=(3, 3, 7), activation='relu')(input_layer)\n",
        "    conv_layer2 = Conv3D(filters=16, kernel_size=(3, 3, 5), activation='relu')(conv_layer1)\n",
        "    conv_layer3 = Conv3D(filters=32, kernel_size=(3, 3, 3), activation='relu')(conv_layer2)\n",
        "    conv_layer3 = Reshape((conv_layer3.shape[1], conv_layer3.shape[2], conv_layer3.shape[3] * conv_layer3.shape[4]))(conv_layer3)\n",
        "    conv_layer4 = Conv2D(filters=64, kernel_size=(3,3), activation='relu')(conv_layer3)\n",
        "    flatten_layer = Flatten()(conv_layer4)\n",
        "    ## fully connected layers\n",
        "    dense_layer1 = Dense(units=256, activation='relu')(flatten_layer)\n",
        "    dense_layer1 = Dropout(0.4)(dense_layer1)\n",
        "    dense_layer2 = Dense(units=128, activation='relu')(dense_layer1)\n",
        "    dense_layer2 = Dropout(0.4)(dense_layer2)\n",
        "    output_layer = Dense(units=output_units, activation='softmax')(dense_layer2)\n",
        "    # define the model with input layer and output layer\n",
        "    model = Model(inputs=input_layer, outputs=output_layer)\n",
        "    # compiling the model\n",
        "    adam = keras.optimizers.Adam(learning_rate=0.001, decay=1e-06)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def train_model(model, X_train, y_train, batch_size=256, epochs=50):\n",
        "    history = model.fit(x=X_train, y=np_utils.to_categorical(y_train), batch_size=batch_size, epochs=epochs)\n",
        "    return history\n",
        "\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    return np.argmax(model.predict(X_test), axis=1)\n",
        "\n",
        "def predict_model(model, X, patch_size, K):\n",
        "    width, height = X.shape[1], X.shape[0]\n",
        "    X = hsi.principal_components(X, n_components=K)\n",
        "    X_pred = create_patches(X, patch_size)\n",
        "    y_pred = np.argmax(model.predict(X_pred), axis=1)\n",
        "    output = np.zeros((height, width))\n",
        "    for i in range(height):\n",
        "        for j in range(width):\n",
        "            k = i * width + j\n",
        "            output[i, j] = y_pred[k]\n",
        "    return output.astype(int)\n",
        "\n",
        "def plot_train_history(history):\n",
        "    plt.ylim(0, 1.01)\n",
        "    plt.grid()\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.legend(['Training loss','Test accuracy'], loc='upper right')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-08-24 12:14:00.506759: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
            "2021-08-24 12:14:00.506817: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
          ]
        }
      ],
      "metadata": {
        "id": "aQrD4-NsakMy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "model = create_model(patch_size, K, len(class_names))\n",
        "history = train_model(model, X_train, y_train)\n",
        "plot_train_history(history)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'class_names' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_8792/3506328024.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput_units\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindowSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_units\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplot_train_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'class_names' is not defined"
          ]
        }
      ],
      "metadata": {
        "id": "lG5pqEMyy4Wl",
        "outputId": "c8b37b55-3ee2-4220-aece-8bdfc03be2e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "y_pred = evaluate_model(model, X_test, y_test)\n",
        "\n",
        "print('Overall accuracy', accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred, target_names=class_names))\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classification results"
      ],
      "metadata": {
        "id": "AVGNYrtLy4Wp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "output = predict_model(model, X, patch_size, K)"
      ],
      "outputs": [],
      "metadata": {
        "id": "VTpCC5BQakM4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "plt.subplot(121)\n",
        "plt.title('Ground truth')\n",
        "plt.imshow(y, cmap='nipy_spectral')\n",
        "plt.axis('off')\n",
        "plt.subplot(122)\n",
        "plt.title('Classification')\n",
        "plt.imshow(output, cmap='nipy_spectral')\n",
        "plt.axis('off')"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'plt' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_10963/3652781748.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m121\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Ground truth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'nipy_spectral'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m122\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "69jjWgjQakM5",
        "outputId": "9dc36762-f282-4d37-f535-68117b608e89"
      }
    }
  ]
}